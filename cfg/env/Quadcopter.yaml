# ======== Asset ========
# Bodies:
#   0: 'base'
#   1: 'motor1_link' low left ccw
#   2: 'motor2_link' low right cw
#   3: 'motor3_link' top left cw
#   4: 'motor4_link' top right ccw
# DOFs:
#   0: 'motor1_joint' (Revolute)
#   1: 'motor2_joint' (Revolute)
#   2: 'motor3_joint' (Revolute)
#   3: 'motor4_joint' (Revolute)

env_name: Quadcopter

num_envs: 1024

total_episodes: 70
max_episode_length: 500

envSpacing: 1.25
clipActions: 1.0

observation:
  add_noise: True 
  scale: True
  clipObservations: 5.0

feature:
  # features
  names: ['angle_rp', 'angle_rp_cd', 'angle_y', 'angle_y_cd', 'low_spin_rp', 'low_spin_y', 'act_smooth']
  verbose: False

task:
  verbose: False

  with_thrust: False # enable thrust, action space increase by 1 dimension
  with_yaw: True # enable yaw, action space increase by 1 dimension

  difficulty: 0.2 # range of the initial robot and goal state [0, 1], serve as maximum difficulty for curriculum as well
  sampling_bound: 0.75 # reduce sampling range to prevent constant reset of env 

  spawn_height: 0 # spawn height of the vehicle and serves as target position for many tasks
  pos_lim: 999999.999999 # radius of the flight zone
  vel_lim: 30.0 # [m/s]
  avel_lim: 15.7 # 5*pi [rad/s]
  rand_rb_pos: False
  rand_rb_vel: False
  rand_rb_ang: True 
  rand_rb_avel: True 
  rand_rb_actuator: True 
  init_pos: [0,0,0]  # only matter if rand_rb_pos is False, global frame, z w.r.t spawn_height
  init_vel: [0,0,0]  # only matter if rand_rb_vel is False, global frame
  init_ang: [0,0,0]  # only matter if rand_rb_ang is False
  init_avel: [0,0,0] # only matter if rand_rb_avel is False, global frame

  taskSet: # allow addition by comma, e.g. "XSet, YSet"
    train: "AttSet, ActSmoothAttSet, QRStabilizeSet, QRYawControlTaskSetObj, QRAngleControlTaskSetObj, PoseRecoverSet" 
    eval: "EvalSet, AttSet, ActSmoothAttSet, QRStabilizeSet, QRYawControlTaskSetObj, QRAngleControlTaskSetObj, PoseRecoverSet" 

    # each taskSet has different goal range, robot initial state, and reset condition, find them in taskset.py
    # if conditions are not defined, using the default random goal, robot state, and reset condition
    # we use this mark "*" to note whether a taskset has sample and reset condition defined
    AttSet: [ 
      [  1,1,1,1,  0, 0, 0],  
      [  1,1,1,1, .3,.3, 0],  
      [  1,1,1,1,  0,.3, 0],  
      [  1,1,1,0, .3,.3, 0],  
      [  1,1,0,0,  0,.3, 0],  
      [ 1,1,1,.3, .3,.3, 0],  
      [ 1,1,1,.3,  0,.3, 0],  
      [  1,0,1,0, .3,.3, 0],  
      [  1,0,1,0,  0,.3, 0],  
      [.3,.3,1,1, .3,.3, 0],  
      [.3,.3,1,1,  0,.3, 0],  
      [ .3,0,1,0, .3,.3, 0],  
      [ .3,0,1,0,  0,.3, 0],  
    ]

    ActSmoothAttSet: [ 
      [  1,1,1,1,  0, 0, .3],  
      [  1,1,1,1, .3,.3, .3],  
      [  1,1,1,1,  0,.3, .3],  
      [  1,1,1,0, .3,.3, .3],  
      [  1,1,0,0,  0,.3, .3],  
      [ 1,1,1,.3, .3,.3, .3],  
      [ 1,1,1,.3,  0,.3, .3],  
      [  1,0,1,0, .3,.3, .3],  
      [  1,0,1,0,  0,.3, .3],  
      [.3,.3,1,1, .3,.3, .3],  
      [.3,.3,1,1,  0,.3, .3],  
      [ .3,0,1,0, .3,.3, .3],  
      [ .3,0,1,0,  0,.3, .3],  
    ]
    QRStabilizeSet: [ # "*" maintain QR pose from random neutral state
      [  1,1,1,1,  0, 0, 0],  
      [  1,1,1,1, .3,.3, 0],  
      [  1,1,1,1,  0,.3, 0],  
      [  1,1,1,0, .3,.3, 0],  
      [  1,1,0,0,  0,.3, 0],  
      [ 1,1,1,.3, .3,.3, 0],  
      [ 1,1,1,.3,  0,.3, 0],  
      [  1,0,1,0, .3,.3, 0],  
      [  1,0,1,0,  0,.3, 0],  
      [.3,.3,1,1, .3,.3, 0],  
      [.3,.3,1,1,  0,.3, 0],  
      [ .3,0,1,0, .3,.3, 0],  
      [ .3,0,1,0,  0,.3, 0],  
    ]
    QRYawControlTaskSetObj: [ # "*" track yaw angle from neutral state
      [  1,1,1,1,  0, 0, 0],  
      [  1,1,1,1, .3,.3, 0],  
      [  1,1,1,1,  0,.3, 0],  
      [ 1,1,1,.3, .3,.3, 0],  
      [ 1,1,1,.3,  0,.3, 0],  
      [.3,.3,1,1, .3,.3, 0],  
      [.3,.3,1,1,  0,.3, 0],  
    ]

    QRAngleControlTaskSetObj: [ # "*" track target angle from neutral state
      [  1,1,1,1,  0, 0, 0],  
      [  1,1,1,1, .3,.3, 0],  
      [  1,1,1,1,  0,.3, 0],  
      [ 1,1,1,.3, .3,.3, 0],  
      [ 1,1,1,.3,  0,.3, 0],  
      [.3,.3,1,1, .3,.3, 0],  
      [.3,.3,1,1,  0,.3, 0],  
    ]
    
    PoseRecoverSet: [ # "*" target QR pose from random init state
      [ 1,0,.3,0,  0,0, .3],  
      [ 1,0,.3,0,  0,0,  0],  
      [  1,0,0,0,  0,0, .3],  
      [  1,0,0,0,  0,0,  0],  
    ]

    EvalSet: [
      [  1,1,1,1,   0,0, .3],  
      [  1,1,1,1,   0,0,  0],  
      [  1,1,1,1, .3,.3,  0],  
      [.3,.3,1,1, .3,.3,  0],  
      [  1,1,0,0, .3,.3,  0],  
      [  1,0,1,0, .3,.3,  0],  
      [.3,.3,1,1,   0,0,  0],  
      [  1,1,0,0,   0,0,  0],  
      [  1,0,1,0,   0,0,  0],  
    ]

    SingleSet: [ # single task for testing
      [  1,1,1,1,  .3, .3, .3]
    ]

goal:
  visualize_goal: False

  goal_type: "random" # [fix, random]
  position_target_type: "center" # [waypoints, center]
  wps_shape: "circle" # waypoints shape, only matter if position_target_type is waypoints
  trigger_dist: 1 # distance to trigger a waypoint, only matter if position_target_type is waypoints
  # below only matter if goal_type is random
  rand_vel: False
  rand_velnorm: False
  rand_ang: False 
  rand_angvel: False
  # the maximum value from random goal 
  lim_vel: 25 
  lim_ang: [3.14159,3.14159,6.28318]
  lim_angvel: [1,1,1]
  # below only matters if rand_X is False or goal type is fix
  target_velnorm: 19 # target forward velocity 
  target_ang: [0,0,0] 
  target_angvel: [0,0,0] # body frame

dynamics:
  add_ground: False 

  # model
  model_frame: "f450" # [f450, iris]
  body_area: [0.0115, 0.0115, 0.0529] # f450 and iris have similar dimension

  # rotors 
  visualize_force: False
  control_interface: "attitude" # rotors, attitude
  control_authority: 0.25 # allowed actuator changes
  rotor_bodies: [1,2,3,4]
  upward: [0, 0, 1] # upward direction
  max_rotor_rpm: 8264 # max rpm of the rotors
  cw: [-1,1,1,-1] # cw +1, ccw -1
  sim_to_real_ratio: 0.2 # an empirical ratio to convert sim to real thrust
  C_T: 0.1 # thrust coefficient
  C_Q: 0.016 # torque coefficient
  C_M: 0.000001 # drag coefficient
  time_constant_up: 0.0125 
  time_constant_down: 0.025
  rotor_drag_coefficient: 8.06428e-5
  propeller_inertia: 0.000451612
  # pre-computed constant, rho(air density): 1.225[kg/m^3], A(area): pi*D^2/4, D(propeller diameter): 0.254[m]
  rho_A_D_pow_2: 0.004004615615878135 

  apply_air_drag: True
  apply_gyroscopic_torque: False # This doesn't matter in low velocity buy may increase computation.
  apply_rolling_moment: True

  enable_wind: False 
  wind_to_velocity_ratio: [10, 10, 1] # wind velocity 

  domain_rand: False 
  latent_range_typeA: [0.67, 1.5] # C_T, C_Q, time_constant
  latent_range_typeB: [0.5, 2.0] # C_M
  latent_range_typeC: [0.8, 1.2] # sim_to_real_ratio, thrust_imbalance, hover_state

sim:
  sim_device: "cuda:0"
  headless: True
  compute_device_id: 0
  graphics_device_id: 0

  dt: 0.01
  substeps: 1
  up_axis: "z"
  use_gpu_pipeline: True
  gravity: [0.0, 0.0, -9.81]
  physx:
    num_threads: 4
    solver_type: 1
    use_gpu: True # set to False to run on CPU
    num_position_iterations: 4
    num_velocity_iterations: 0
    contact_offset: 0.02
    rest_offset: 0.001
    bounce_threshold_velocity: 0.2
    max_depenetration_velocity: 1000.0
    default_buffer_size_multiplier: 5.0
    max_gpu_contact_pairs: 1048576 # 1024*1024
    num_subscenes: 4
    contact_collection: 0 # 0: CC_NEVER (don't collect contact info), 1: CC_LAST_SUBSTEP (collect only contacts on last substep), 2: CC_ALL_SUBSTEPS (broken - do not use!)

# only useful for graph SAC
graph:
  # Action index: a_r[0], a_p[1], a_y[2]
  # State index: roll[3], pitch[4], yaw[5], ω_r[6], ω_p[7], ω_y[8]
  # Goal index: g_r[9], g_p[10], g_y[11]
  # Environment index: 'e0'[12], 'e1'[13] --> only used with RMA
  positive_edge: # store positive connection between states and actions
    {
      0: [0,3,6,12], # roll
      1: [1,4,7,12], # pitch
      2: [2,5,8,13], # yaw
    }
  negative_edge: # store negative connection between states and actions
    {
      0: [9], # roll
      1: [10], # pitch
      2: [11], # yaw
    }

# only useful for graph MTSAC
graph_with_task:
  # Action index: a_r[0], a_p[1], a_y[2]
  # State index: roll[3], pitch[4], yaw[5], ω_r[6], ω_p[7], ω_y[8]
  # Goal index: g_r[9], g_p[10], g_y[11]
  # Task index: 'angle_rp'[12], 'angle_rp_cd'[13], 'angle_y'[14], 'angle_y_cd'[15], 'low_spin_rp'[16], 'low_spin_y'[17], 'act_smooth'[18]
  # Environment index: 'e0'[19], 'e1'[20] --> only used with RMA
  positive_edge: # store positive connection between states and actions
    {
      0: [0,3,6,12,13,16,18,19], # roll
      1: [1,4,7,12,13,16,18,19], # pitch
      2: [2,5,8,14,15,17,18,20], # yaw
    }
  negative_edge: # store negative connection between states and actions
    {
      0: [9], # roll
      1: [10], # pitch
      2: [11], # yaw
    }
